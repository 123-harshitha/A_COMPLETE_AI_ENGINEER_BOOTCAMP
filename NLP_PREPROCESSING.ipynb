{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "421ad22d-98dd-41c0-9205-d1d9a0c6b6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey cat's name is luna\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Hey Cat's name is Luna\"\n",
    "lower_sentence = sentence.lower()      \n",
    "print(lower_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9eb82a-77cc-4bb4-89a2-c233fbbe2b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. CONVERTING TO THE LOWERCASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07e801ef-2983-4b8b-99de-62074f8df1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Could you pass me the TV remote?', 'It is IMPOSSIBLE to find this hotel', 'Want to go for dinner on Tuesday?']\n"
     ]
    }
   ],
   "source": [
    "sentence_list = ['Could you pass me the TV remote?', \n",
    "                 'It is IMPOSSIBLE to find this hotel', \n",
    "                 'Want to go for dinner on Tuesday?']\n",
    "print(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9225e60b-9351-4361-8c42-4d4d4f0855e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['could you pass me the tv remote?', 'it is impossible to find this hotel', 'want to go for dinner on tuesday?']\n"
     ]
    }
   ],
   "source": [
    "lower_sentence_list = [x.lower() for x in sentence_list]\n",
    "print(lower_sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cf40ac-fd85-47c7-b21f-e5bb7a5ac36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "2.2  REMOVING THE STOP WORDS \n",
    "\n",
    "Stop words are common words in the language which don't carry much meaning e.g. \"and\", \"of\", \"a\", \"to\".\n",
    "\n",
    "We remove these words because it removes a lot of complexity from the data. \n",
    "These words don't add much meaning to text so by removing them we are left with a smaller, cleaner dataset. Smaller, cleaner datasets often lead to increased accuracy in machine learning and will also speed up processing times.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4747173-5fe1-466c-a019-2e62466b817b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\harsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "464430d6-58a7-44ed-b183-55590fe39e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d338001-d811-46c2-8214-4466eb45b6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n"
     ]
    }
   ],
   "source": [
    "print(en_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bbf7e98-49e8-420e-8e4b-a8b96668fc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentence = \"it was too far to go to the shop and he did not want her to walk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a7d1ee0-9c40-42f6-94cf-da98fcc26688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "far go shop want walk\n"
     ]
    }
   ],
   "source": [
    "#keep the word in the sentence if the word is not in the list of the stop words\n",
    "\n",
    "sentence_no_stopwords = ' '.join([word for word in sentence.split() if word not in(en_stopwords)])\n",
    "print(sentence_no_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65b436c1-c258-4e51-a222-9bce890a2fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the stopwords from the list\n",
    "\n",
    "en_stopwords.remove(\"did\")\n",
    "en_stopwords.remove(\"not\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81fc1a21-b007-4b35-8e8f-50dd078674cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the custom stop words \n",
    "\n",
    "en_stopwords.append(\"go\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7357e623-4ff3-43bb-a54f-1234c4e15d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "far go shop want walk\n"
     ]
    }
   ],
   "source": [
    "sentence_no_stop_words_custom = ' '.join([word for word in sentence.split() if word not in (en_stopwords)])\n",
    "print(sentence_no_stop_words_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c04995-afbd-4b07-bea6-cf05f12698fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
